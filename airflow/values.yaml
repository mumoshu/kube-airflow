airflow:
  # common settings and setting for the webserver
  # For prefix, use only lower case alphanumeric characters, '-' or '.', and must start and end
  # with an alphanumeric character
  prefix: ""
  fernet_key: ""
  service:
    type: ClusterIP
  dag_path: /dags
  init_retry_loop:
  image: mumoshu/kube-airflow:1.8.0.0-1.6.1
  # image_pull_policy: Always or IfNotPresent
  image_pull_policy: Always
  # Set scheduler_num_runs to -1 to loop indefinitively
  scheduler_num_runs: "-1"
  url_prefix: ""
  # airflow-cfg allow you to override the whole content of airflow.cfg at once
  # BEWARE of maintaining uniformity in your configuration, especially since the bootstrap script
  # `entrypoint.sh` will not adapt the various settings accordingly to this configuration, such as
  # rabbitmq/postgres creds/host, git-sync etc.
  # If you choose to hardcode a complete file, just ensure you have the same configuration as
  # defined here (remember the postgres/rabbitmq hostnames are prepended by a prefix defined in
  # `airflow.prefix`). If you use templating you can still look at the example in
  # `values-airflowcfg.yaml`.
  airflow_cfg:
    enable: false
    data:

celery:
  num_workers: 1

ingress:
  enabled: false
  annotations:
  host: ""
  path:
    web: /airflow
    flower: /flower

db:
  rabbitmq:
    # use_embedded == true means final hostname will be prefix + basename
    use_embedded: true
    user: airflow
    password: airflow
    basename: rabbitmq
    database: airflow
  postgres:
    # use_embedded == true means final hostname will be prefix + basename
    use_embedded: true
    user: airflow
    password: airflow
    basename: postgres
    database: airflow

persistence:
  enabled: false
  ## storageClass: Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  # storageClass: default
  accessMode: ReadWriteOnce
  size: 1Gi


flower:
  url_prefix: ""

dags:
  # Use of git-sync: beware when using git-sync and airflow. If the scheduler reloads a dag in the
  # middle of a dagrun then the dagrun will actually start using the new version of the dag in the
  # middle of execution.
  # This is a known issue with airflow and it means it's unsafe in general to use a git-sync
  # like solution with airflow without:
  # - using explicit locking, ie never pull down a new dag if a dagrun is in progress
  # - make dags immutable, never modify your dag always make a new one
  git_sync_enabled: false
  git_repo:
  git_branch: master
  poll_interval_sec: 60
  git_sync_debug: false
  # Disable Load examples as soon as you enable git_repo
  load_examples: true
